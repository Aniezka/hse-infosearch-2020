{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9MsvxXsHar3",
    "outputId": "e80143a6-964b-4779-94e4-93449152cdaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0, 1.0, 2.0}"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7sTDyePHar6"
   },
   "source": [
    "Читаем информацию о группах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EvrJJEhSHar7"
   },
   "outputs": [],
   "source": [
    "group_train = []\n",
    "with open(\"data/mq2008.train.group\", \"r\") as f:\n",
    "    data = f.readlines()\n",
    "    for line in data:\n",
    "        group_train.append(int(line.split(\"\\n\")[0]))\n",
    "\n",
    "group_valid = []\n",
    "with open(\"data/mq2008.vali.group\", \"r\") as f:\n",
    "    data = f.readlines()\n",
    "    for line in data:\n",
    "        group_valid.append(int(line.split(\"\\n\")[0]))\n",
    "\n",
    "group_test = []\n",
    "with open(\"data/mq2008.test.group\", \"r\") as f:\n",
    "    data = f.readlines()\n",
    "    for line in data:\n",
    "        group_test.append(int(line.split(\"\\n\")[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVRlUm-WHar-"
   },
   "source": [
    "Как устроена информация о группах:\n",
    "* количество групп отражает информацию о количестве запросов\n",
    "* каждое число обозначает количество последовательных объектов, которые в эту группу объединяются\n",
    "* из предыдущего пункта следует, что в X объекты нельзя перемешивать\n",
    "* если просуммировать все числа в списке групп, получим число объектов из X\n",
    "\n",
    "Для чего нужны группы? <br>\n",
    "Для того, чтобы в обучении не сравнивать доки из разных групп (разных запросов) между собой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G7cSNYBvHar-",
    "outputId": "25d51c98-aacf-4859-e81b-f44a024c383f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471 9630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8, 8, 8, 8, 8, 16, 8, 118, 16, 8]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(group_train), sum(group_train))\n",
    "group_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5BJePVkHasC"
   },
   "source": [
    "Обучаем модель. <br>\n",
    "С помощью `eval_set` можем контролировать обучение, но это необязательный параметр, можно обучить и без валидации. <br>\n",
    "В параметре `objective` можно задать три опции: `rank:ndcg`, `rank:pairwise`, `rank:map`. `ndcg` и `map` регулияруют попарный лосс с помощью подсчета соответствующих метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mslzPNUkHasD",
    "outputId": "ca16a731-3546-4d39-9461-a9e9c29611de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval_0-map:0.71552\n",
      "[1]\teval_0-map:0.72606\n",
      "[2]\teval_0-map:0.72795\n",
      "[3]\teval_0-map:0.73352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRanker(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "          colsample_bynode=1, colsample_bytree=1, gamma=1.0, gpu_id=-1,\n",
       "          importance_type='gain', interaction_constraints='', learning_rate=0.1,\n",
       "          max_delta_step=0, max_depth=6, min_child_weight=0.1, missing=nan,\n",
       "          monotone_constraints='()', n_estimators=4, n_jobs=0,\n",
       "          num_parallel_tree=1, objective='rank:ndcg', random_state=0,\n",
       "          reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "          tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'objective': 'rank:ndcg', 'learning_rate': 0.1,\n",
    "          'gamma': 1.0, 'min_child_weight': 0.1,\n",
    "          'max_depth': 6, 'n_estimators': 4}\n",
    "\n",
    "model = xgb.sklearn.XGBRanker(**params)\n",
    "model.fit(x_train, y_train, group_train, verbose=True,\n",
    "          eval_set=[(x_valid, y_valid)], eval_group=[group_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBYNA6rlHasG"
   },
   "source": [
    "Получим предсказание на тестовом сете:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YwLv8-R_HasG"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oU5jjCqMHasJ"
   },
   "source": [
    "Посчитаем качество:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ig0a61mzHasK"
   },
   "outputs": [],
   "source": [
    "start_idx = 0\n",
    "grouped_pred = []\n",
    "grouped_target = []\n",
    "\n",
    "for group_n in group_test:\n",
    "    grouped_pred.append(pred[start_idx:start_idx+group_n])\n",
    "    grouped_target.append(y_test[start_idx:start_idx+group_n])\n",
    "    start_idx += group_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "InY__2YFHasN",
    "outputId": "3940fbdc-cb50-4c79-868b-08afeb8fb3b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5052327963105946"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([\n",
    "    ndcg_score([grouped_target[i]], [grouped_pred[i]])\n",
    "    for i in range(len(grouped_target))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EqDdst-HasS"
   },
   "source": [
    "# Семинар и дз\n",
    "Сделать и улучшить любую ML-модель на ваших проектных данных (просто клф, бленд, ранжирование, что-то что вы придумали сами...), используя любые признаки, какие захотите. Оцениваться будут:\n",
    "* факт выполнения задания :)\n",
    "* корректность кода (чтобы код не падал) и отсутствие логических ошибок (e.g. затестили на трейне)\n",
    "* итеративность улучшения (например взяли один сет признаков, показали качество; потом добавили / подкрутили / использовали другую модель, показали качество...)\n",
    "* креативность признаков\n",
    "* аккуратность ноутбука\n",
    "\n",
    "Дедлайн: 15 октября"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "XM0gHkwdHasS",
    "outputId": "821f5e31-379a-42b8-dbb2-496af8ce60a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "### реализуйте эту функцию ранжирования \n",
    "import collections\n",
    "import string\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from razdel import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from yargy import or_\n",
    "from yargy.predicates import caseless, normalized, dictionary\n",
    "from yargy import rule, and_, Parser\n",
    "from yargy.predicates import gte, lte\n",
    "\n",
    "nltk.download('stopwords')\n",
    "morph = MorphAnalyzer()\n",
    "stop = set(stopwords.words('russian'))\n",
    "\n",
    "\n",
    "def my_preprocess(text: str):\n",
    "    text = str(text)\n",
    "    text = text.replace(\"\\n\", \" \").replace('/', ' ')\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokenized_text = list(tokenize(text))\n",
    "    lemm = [morph.parse(i.text)[0].normal_form for i in tokenized_text]\n",
    "    words = [i for i in lemm if i not in stop]\n",
    "#     return words\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQD5M5CoXFDf"
   },
   "source": [
    "### Загрузим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "E4QChta8HasY",
    "outputId": "82362027-5f65-4216-de05-7404bc97a6f5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-16b93b2e-9f40-49e2-b0fd-cc136c01b584\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-16b93b2e-9f40-49e2-b0fd-cc136c01b584\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving answers_base.xlsx to answers_base (6).xlsx\n",
      "Saving queries_base.xlsx to queries_base (6).xlsx\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# answers_df = pd.read_excel(\"answers_base.xlsx\")\n",
    "answers_df = pd.read_excel(io.BytesIO(uploaded['answers_base.xlsx']))\n",
    "\n",
    "# questions_df = pd.read_excel(\"queries_base.xlsx\")\n",
    "questions_df = pd.read_excel(io.BytesIO(uploaded['queries_base.xlsx']))\n",
    "\n",
    "# df = pd.read_csv(io.StringIO(uploaded['train.csv'].decode('utf-8')))\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwkyhnDdXKpn"
   },
   "source": [
    "### Составим TF-IDF вектора и посчитаем accyracy обычного перемножения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82
    },
    "id": "tvgmVwwsQBnj",
    "outputId": "6cc6d64f-e90e-4733-f0c5-433712776cf1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1652/1652 [00:27<00:00, 60.68it/s]\n",
      "100%|██████████| 690/690 [00:11<00:00, 61.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (1652, 7407)\n",
      "X_test.shape: (690, 7407)\n"
     ]
    }
   ],
   "source": [
    "full_corpus = []\n",
    "\n",
    "answers_df.rename(columns={'Текст вопросов': 'text', 'Номер связки': 'join_num'}, inplace=True)\n",
    "questions_df.rename(columns={'Текст вопроса': 'text', 'Номер связки\\n': 'join_num'}, inplace=True)\n",
    "\n",
    "train, test_quest = train_test_split(questions_df, test_size=0.3)\n",
    "\n",
    "train_quest = pd.concat([answers_df, train])\n",
    "\n",
    "train_quest_processed = []\n",
    "test_quest_processed = []\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# preprocess train / test\n",
    "for quest in tqdm(train_quest['text']):\n",
    "    train_quest_processed.append(my_preprocess(quest))\n",
    "for quest in tqdm(test_quest['text']):\n",
    "    test_quest_processed.append(my_preprocess(quest))\n",
    "    \n",
    "vectorizer.fit(train_quest_processed)\n",
    "# train matrix\n",
    "X_train = vectorizer.transform(train_quest_processed)\n",
    "# test natrix\n",
    "X_test = vectorizer.transform(test_quest_processed)\n",
    "\n",
    "print(\"X_train.shape: \" + str(X_train.shape))\n",
    "print(\"X_test.shape: \" + str(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "_xyFvFJ-Hasb",
    "outputId": "af63b03c-34bb-4536-f37d-146998a1ce10"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Accuracy with natasha and TF-IDF: 0.5347826086956522'"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = X_train.dot(X_test.T).argmax(axis=0)\n",
    "rating = np.array(rating)[0]\n",
    "count = 0\n",
    "for ind_test, pred in enumerate(rating):\n",
    "    if math.isnan(test_quest.iloc[ind_test].join_num) or math.isnan(train_quest.iloc[pred].join_num):\n",
    "        continue\n",
    "\n",
    "    if int(test_quest.iloc[ind_test].join_num) == int(train_quest.iloc[pred].join_num):\n",
    "        count += 1\n",
    "\n",
    "\"Accuracy TF-IDF: \" + str(count / len(rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fu9gMlnQXTaQ"
   },
   "source": [
    "### Попробуем удалить NER дат и поосмотрим результат после\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "id": "9L8GybkDHash",
    "outputId": "4d6310f2-8ebd-4a31-c5f2-d1facef55f81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 19) ['8', 'января', '2014', 'года']\n",
      "[21, 36) ['15', 'июня', '2001', 'г', '.']\n",
      "[38, 53) ['31', 'февраля', '2018']\n",
      "[60, 70) ['8', '-', '9', 'ноября']\n",
      "[85, 92) ['5', 'числа']\n",
      "[93, 106) ['20', 'го', 'сентября']\n"
     ]
    }
   ],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    NewsEmbedding,\n",
    "    NewsNERTagger,\n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "    DatesExtractor,\n",
    "\n",
    "    Doc\n",
    ")\n",
    "\n",
    "\n",
    "from yargy import or_\n",
    "from yargy.predicates import caseless, normalized, dictionary\n",
    "from yargy import rule, and_, Parser\n",
    "from yargy.predicates import gte, lte\n",
    "\n",
    "\n",
    "DAY = and_(\n",
    "    gte(1),\n",
    "    lte(31)\n",
    ")\n",
    "MONTH = and_(\n",
    "    gte(1),\n",
    "    lte(12)\n",
    ")\n",
    "YEAR = and_(\n",
    "    gte(1),\n",
    "    lte(2018)\n",
    ")\n",
    "DATE = rule(\n",
    "    YEAR,\n",
    "    '-',\n",
    "    MONTH,\n",
    "    '-',\n",
    "    DAY\n",
    ")\n",
    "\n",
    "\n",
    "MONTHS = {\n",
    "    'январь',\n",
    "    'февраль',\n",
    "    'март',\n",
    "    'апрель',\n",
    "    'мая',\n",
    "    'июнь',\n",
    "    'июль',\n",
    "    'август',\n",
    "    'сентябрь',\n",
    "    'октябрь',\n",
    "    'ноябрь',\n",
    "    'декабрь'\n",
    "}\n",
    "MONTH_NAME = dictionary(MONTHS)\n",
    "YEAR_WORDS = or_(\n",
    "    rule(caseless('г'), '.'),\n",
    "    rule(normalized('год')),\n",
    "    rule(normalized('число')),\n",
    "    rule(caseless('числа')),\n",
    "    rule(caseless('го'))\n",
    ")\n",
    "\n",
    "DATE = or_(\n",
    "    rule(\n",
    "        YEAR,\n",
    "        '-',\n",
    "        MONTH,\n",
    "        '-',\n",
    "        DAY\n",
    "    ),\n",
    "    rule(\n",
    "        DAY,\n",
    "        MONTH_NAME,\n",
    "        YEAR,\n",
    "        YEAR_WORDS.optional()\n",
    "    ),\n",
    "    rule(\n",
    "        DAY,\n",
    "        \"-\",\n",
    "        DAY,\n",
    "        MONTH_NAME,\n",
    "    ),\n",
    "    rule(\n",
    "        DAY,\n",
    "        YEAR_WORDS.optional(),\n",
    "        MONTH_NAME.optional()\n",
    "    )\n",
    ")\n",
    "\n",
    "parser = Parser(DATE)\n",
    "text = '''\n",
    "8 января 2014 года, 15 июня 2001 г.,\n",
    "31 февраля 2018\n",
    "Уехал 8-9 ноября в Сочи\n",
    "Уезжаю 5 числа\n",
    "20го сентября заболел'''\n",
    "for match in parser.findall(text):\n",
    "    print(match.span, [_.value for _ in match.tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oooT4XSMHasj"
   },
   "outputs": [],
   "source": [
    "parser = Parser(DATE)\n",
    "segmenter = Segmenter()\n",
    "emb = NewsEmbedding()\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "\n",
    "def preprocess_with_natasha_date(text: str) -> str:\n",
    "    text = str(text)\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_ner(ner_tagger)\n",
    "    for ner in doc.spans:\n",
    "        text = text[0:ner.start] + text[ner.stop:]\n",
    "    for match in parser.findall(text):\n",
    "        for tok in match.tokens:\n",
    "            text = text[0:tok.span.start] + text[tok.span.stop:]\n",
    "    return \" \".join(text.split())\n",
    "#     return my_preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82
    },
    "id": "Iign6sH2K3t7",
    "outputId": "2176589e-6441-4507-b898-df927797b210"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1652/1652 [00:43<00:00, 38.34it/s]\n",
      "100%|██████████| 690/690 [00:17<00:00, 39.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (1652, 14550)\n",
      "X_test.shape: (690, 14550)\n"
     ]
    }
   ],
   "source": [
    "train_quest_processed = []\n",
    "test_quest_processed = []\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# preprocess train / test\n",
    "for quest in tqdm(train_quest['text']):\n",
    "    train_quest_processed.append(preprocess_with_natasha_date(quest))\n",
    "for quest in tqdm(test_quest['text']):\n",
    "    test_quest_processed.append(preprocess_with_natasha_date(quest))\n",
    "\n",
    "vectorizer.fit(train_quest_processed)\n",
    "# train matrix\n",
    "X_train = vectorizer.transform(train_quest_processed)\n",
    "# test natrix\n",
    "X_test = vectorizer.transform(test_quest_processed)\n",
    "\n",
    "print(\"X_train.shape: \" + str(X_train.shape))\n",
    "print(\"X_test.shape: \" + str(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ouTXOJr7Hasm",
    "outputId": "ddc118f7-64f9-4c24-c376-4ebc0b9e0d78"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Accuracy with natasha and TF-IDF: 0.5159420289855072'"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = X_train.dot(X_test.T).argmax(axis=0)\n",
    "rating = np.array(rating)[0]\n",
    "count = 0\n",
    "for ind_test, pred in enumerate(rating):\n",
    "    if math.isnan(test_quest.iloc[ind_test].join_num) or math.isnan(train_quest.iloc[pred].join_num):\n",
    "        continue\n",
    "\n",
    "    if int(test_quest.iloc[ind_test].join_num) == int(train_quest.iloc[pred].join_num):\n",
    "        count += 1\n",
    "\n",
    "\"Accuracy with yargy NER date deleting and TF-IDF: \" + str(count / len(rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bobimIS8Xh_u"
   },
   "source": [
    "### Результат уменьшился, тогда посмотрим как работает градиентный бустинг без удаления NER на векторах TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "CLZjzdDfKK7F",
    "outputId": "aec1e7b8-2115-48c2-dcfc-e469bb6989f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (1646, 7463)\n",
      "X_test.shape: (687, 7463)\n"
     ]
    }
   ],
   "source": [
    "full_corpus = []\n",
    "\n",
    "answers_df = answers_df.rename(columns={'Текст вопросов': 'text', 'Номер связки': 'join_num'})\n",
    "answers_df = answers_df.dropna(subset=['join_num'])\n",
    "\n",
    "questions_df = questions_df.rename(columns={'Текст вопроса': 'text', 'Номер связки\\n': 'join_num'})\n",
    "questions_df = questions_df.dropna(subset=['join_num'])\n",
    "\n",
    "answers_df['normal_text'] = answers_df['text'].apply(my_preprocess)\n",
    "questions_df['normal_text'] = questions_df['text'].apply(my_preprocess)\n",
    "\n",
    "\n",
    "train, test_quest, y_train, y_test = train_test_split(questions_df['normal_text'],\n",
    "                                                      questions_df['join_num'],\n",
    "                                                      test_size=0.3)\n",
    "\n",
    "y_train = pd.concat([answers_df['join_num'], y_train])\n",
    "train_quest = pd.concat([answers_df['normal_text'], train])\n",
    "\n",
    "train_quest_processed = []\n",
    "test_quest_processed = []\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "vectorizer.fit(train_quest)\n",
    "# train matrix\n",
    "X_train = vectorizer.transform(train_quest)\n",
    "# test natrix\n",
    "X_test = vectorizer.transform(test_quest)\n",
    "\n",
    "print(\"X_train.shape: \" + str(X_train.shape))\n",
    "print(\"X_test.shape: \" + str(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "id": "gQxBKcJWM82s",
    "outputId": "a9f4f8c1-60dd-4a19-d6c3-d452484b511c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=1.0,\n",
       "              learning_rate=0.05, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=0.1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 104,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "params = {'objective': 'rank:ndcg', 'learning_rate': 0.05,\n",
    "          'gamma': 1.0, 'min_child_weight': 0.1,\n",
    "          'max_depth': 6, 'n_estimators': 100}\n",
    "\n",
    "model = xgb.sklearn.XGBClassifier(**params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tW3vBW5gR27b"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCbOUICQXrlP"
   },
   "source": [
    "### Градиентный бустинг показывает наилучший результат из всех моделей, которые рассматривались во всех домашних заданиях, поэтому выберем его в качестве финальной модели и найдём оптимальные параметры\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "id": "c6xLO0RMViPk",
    "outputId": "fea19b32-17f3-4d6c-cccb-06b505938587"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6433770014556041\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for ind, i in enumerate(pred):\n",
    "    if i == y_test.values[ind]:\n",
    "        count += 1\n",
    "\n",
    "print(count / len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "fX9lJjlXVi4G",
    "outputId": "adcb2788-8d7b-42e3-af2f-bab95bfd2660"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-17 21:19:27,682]\u001b[0m A new study created in memory with name: no-name-c466fe86-b0ed-46d7-a45c-f4361078ca7d\u001b[0m\n",
      "\u001b[32m[I 2020-10-17 21:20:04,696]\u001b[0m Trial 0 finished with value: 0.6215429403202329 and parameters: {'max_depth': 5, 'n_estimators': 83, 'min_child_weight': 4, 'gamma': 2, 'learning_rate': 0.09545120975343886}. Best is trial 0 with value: 0.6215429403202329.\u001b[0m\n",
      "\u001b[32m[I 2020-10-17 21:20:57,471]\u001b[0m Trial 1 finished with value: 0.6200873362445415 and parameters: {'max_depth': 8, 'n_estimators': 92, 'min_child_weight': 5, 'gamma': 1, 'learning_rate': 0.027233911547249193}. Best is trial 0 with value: 0.6215429403202329.\u001b[0m\n",
      "\u001b[32m[I 2020-10-17 21:21:27,473]\u001b[0m Trial 2 finished with value: 0.6419213973799127 and parameters: {'max_depth': 6, 'n_estimators': 56, 'min_child_weight': 3, 'gamma': 3, 'learning_rate': 0.09772431162992182}. Best is trial 2 with value: 0.6419213973799127.\u001b[0m\n",
      "\u001b[32m[I 2020-10-17 21:22:03,649]\u001b[0m Trial 3 finished with value: 0.5502183406113537 and parameters: {'max_depth': 8, 'n_estimators': 59, 'min_child_weight': 5, 'gamma': 0, 'learning_rate': 0.008873483432129289}. Best is trial 2 with value: 0.6419213973799127.\u001b[0m\n",
      "\u001b[32m[I 2020-10-17 21:22:17,607]\u001b[0m Trial 4 finished with value: 0.5851528384279476 and parameters: {'max_depth': 11, 'n_estimators': 20, 'min_child_weight': 3, 'gamma': 5, 'learning_rate': 0.03207694757544723}. Best is trial 2 with value: 0.6419213973799127.\u001b[0m\n",
      "\u001b[32m[I 2020-10-17 21:22:50,638]\u001b[0m Trial 5 finished with value: 0.6244541484716157 and parameters: {'max_depth': 4, 'n_estimators': 67, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.09586764532775185}. Best is trial 2 with value: 0.6419213973799127.\u001b[0m\n",
      "\u001b[32m[I 2020-10-17 21:23:31,900]\u001b[0m Trial 6 finished with value: 0.5953420669577875 and parameters: {'max_depth': 6, 'n_estimators': 73, 'min_child_weight': 3, 'gamma': 3, 'learning_rate': 0.014920772656905093}. Best is trial 2 with value: 0.6419213973799127.\u001b[0m\n",
      "\u001b[32m[I 2020-10-17 21:24:58,641]\u001b[0m Trial 7 finished with value: 0.5764192139737991 and parameters: {'max_depth': 11, 'n_estimators': 76, 'min_child_weight': 0, 'gamma': 2, 'learning_rate': 0.0063766660383049465}. Best is trial 2 with value: 0.6419213973799127.\u001b[0m\n",
      "\u001b[32m[I 2020-10-17 21:25:36,350]\u001b[0m Trial 8 finished with value: 0.6259097525473072 and parameters: {'max_depth': 7, 'n_estimators': 93, 'min_child_weight': 5, 'gamma': 0, 'learning_rate': 0.22284952541033962}. Best is trial 2 with value: 0.6419213973799127.\u001b[0m\n",
      "\u001b[32m[I 2020-10-17 21:26:06,834]\u001b[0m Trial 9 finished with value: 0.6200873362445415 and parameters: {'max_depth': 5, 'n_estimators': 87, 'min_child_weight': 4, 'gamma': 0, 'learning_rate': 0.43361588712356947}. Best is trial 2 with value: 0.6419213973799127.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "# 1. Define an objective function to be maximized.\n",
    "def fitXGB(trial):\n",
    "    params ={'objective': 'rank:ndcg',\n",
    "            'max_depth':trial.suggest_int('max_depth', 3, 11),\n",
    "            'n_estimators':trial.suggest_int('n_estimators', 10, 100),\n",
    "            'min_child_weight':trial.suggest_int('min_child_weight', 0, 5),\n",
    "            'gamma':trial.suggest_int('gamma', 0, 5),\n",
    "            'learning_rate':trial.suggest_loguniform('learning_rate',0.005,0.5),\n",
    "            'nthread' : -1  \n",
    "    }\n",
    "    count = 0\n",
    "    model = xgb.sklearn.XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train) \n",
    "    pred = model.predict(X_test)\n",
    "    for ind, i in enumerate(pred):\n",
    "        if i == y_test.values[ind]\n",
    "    count += 1\n",
    "\n",
    "    return  count / len(pred)\n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(fitXGB, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPvg5RqeaAxj"
   },
   "source": [
    "### Посмотрим результат с наилучшими найденными параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hxp56K6SZ6Dg"
   },
   "outputs": [],
   "source": [
    "params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "id": "P6U2wtqkZQJG",
    "outputId": "1874f69e-c680-4102-cede-af53a6352f98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=3,\n",
       "              learning_rate=0.09772431162992182, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=3, missing=None, n_estimators=56, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 119,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.sklearn.XGBClassifier(**params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "id": "TqeU6DwKdgPI",
    "outputId": "db982d69-00e9-490b-bd80-656bd58f4ffa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6419213973799127\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "count = 0\n",
    "for ind, i in enumerate(pred):\n",
    "    if i == y_test.values[ind]:\n",
    "        count += 1\n",
    "print(count / len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tT5Hsr84dmDU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sem5_Ranking.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
